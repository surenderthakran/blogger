<h2>What is a Neural Network?</h2>
<p>Neural Networks, more appropriately referred to as an 'Artificial Neural
  Networks' (ANN), are information processing systems that are inspired by the
  biological neural networks such as the brain.
<p>In its simplest form a biological brain is a huge collection of neurons. Each neuron
  takes electrical and chemical signals as inputs through its many dentrites and
  transmits its output signals through its axon (in a more specialized context,
  there are exceptions to this behavior like with multipolar neurons). Axons make contact with other neurons
  at specialized junctions called synapses.</p>
<div class="image">
  <img alt="image illustrating a biological neuron" src="/images/{{ url }}/biological-neuron.png" width="500" />
  <a href="https://en.wikipedia.org/wiki/Neuron" target="_blank">Image source</a>
</div>
<p>Taking inspiration from the brain, an artificial neural network is a
  collection of connected units, also called neurons. The connection between the
  neurons can carry signals between them. Each connection carries a real number
  value which determines the weightage/strength of the signal.</p>
<p>They are <strong>universal function approximators</strong> who at there very essence
  approximate a function/relation between the input data and the output
  data.<p>
<h2>Neurons</h2>
<p>Neurons are the basic building blocks of ANNs. An artificial neuron receives
  one or more inputs and operates on them to produce
  one or more outputs. This is similar to dentrites in a biological neuron
  receiving input signals and sending out an output signal through its axon.</p>
<p>Each input to an artificial neuron is individually weighted to determine the
  <em>strength</em> of each input. A weighted summation of all the inputs
  forms the total net input to a neuron.</p>
<div class="image">
  <img alt="image illustrating an equation to calculate total net input for a neuron" src="/images/{{ url }}/total-net-input.png" width="250" />
</div>
<p>Consider the following diagram of an artificial neuron.</p>
<div class="image">
  <img alt="image illustrating a simple artificial neuron" src="/images/{{ url }}/neuron.png" width="300" />
</div>
<p>In the above neuron, <span class="code">i1</span> and <span class="code">i2</span> are the inputs to the neuron with
  each input having weights <span class="code">w2</span> and <span class="code">w2</span> respectively.
  Hence, the <span class="code">Total Net Input</span> for the neuron would be:</p>
<div class="image">
  <img alt="image illustrating an equation to calculate total net input for the example neuron" src="/images/{{ url }}/example-total-net-input.png" width="250" />
</div>
<p>The neuron then computes the output using an activation function on the Total Net Input.
  The result of the activation function is the output of the neuron.</p>
<div class="image">
  <img alt="image illustrating an equation to calculate output of a neuron" src="/images/{{ url }}/activation.png" width="250" />
</div>
<p>The output of a neuron is forwarded to the next neuron in line as input. In an ANN, the
  results from one layer of neurons are progressively forwarded to the neurons in the next
  layer until they exit from the output layer which forms the output of the
  network.</p>
<h3>Activation Functions</h3>
<p>The Total Net Input to a neuron could be anywhere between <em>+Infinity</em> to <em>-Infinity</em>.
  To decide whether the neuron should fire/activate (i.e. generate an output)
  researchers introduced activation functions inside neurons. Activation
  functions provide complex non-linear functional mapping between the net input
  and output of a neuron.</p>
<p>Without the activation functions, the output of a neuron will just be a
  <a href="https://en.wikipedia.org/wiki/Linear_function" target="_blank">linear function</a>
  of the input. An ANN without a activation function would simply be a
  <a href="https://en.wikipedia.org/wiki/Linear_regression" target="_blank">Linear Regression Model</a>.
  Although, it would be much easier to train such an ANN, they would be limited
  in their complexity and have less capability to learn complex functional
  mappings from complex non-linear data sets like images, audio, video etc.</p>
<p>Unlike linear functions, non-linear functions are polynomials functions of a
  <em>degree more than one</em> and their plottings on a map are curved. For an ANN
  to be able to create non-linear arbitrary and complex mappings between the input and output, we need
  non-linear activation functions.</p>
<p>Another important requirement for an activation function is that it should be
  differentiable so that we can calculate <em>error gradient</em> of the network with respect to its weights.
  This gradient is needed to perform backpropagation optimization strategy.</p>
<p>There are several different activation functions and the choice of activation
  function inside a neuron heavily influences the learning techniques employed
  on the network and vice versa.</p>
<p>Some of the most popular activation functions are:</p>
<ul>
  <li><a href="https://en.wikipedia.org/wiki/Sigmoid_function" target="_blank">Sigmoid (Logistic)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Hyperbolic_function" target="_blank">Tanh (Hyperbolic)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" target="_blank">ReLU (Rectified Linear Unit)</a> etc</li>
</ul>
<p>In the current implementation we would only be using Sigmoid functions.</p>
<h2>Topology Of an Artificial Neural Network</h2>
<p>The neurons in an ANN are arranged in two categories called layers vis hidden layer and output layer.
  In addition to these two layers, there is also a third layer called the input layer which
  doesn't has any neurons but instead just acts as a matrix for the input data.
</p>
<p>One of the simplest form of neural networks is a single hidden layer feed forward neural network.</p>
<div class="image">
  <img alt="image illustrating a basic single hidden layer neural network" src="/images/{{ url }}/basic-neural-network.png" width="600" />
</div>
<h2>Learning History</h2>
<h2>Multi Layer Perceptrons (MLP)</h2>
<h3>Back Propagation Algorithm</h3>
<p>Backpropagation, short for "backward propagation of errors," is an algorithm
  for supervised learning of artificial neural networks using gradient descent.
  Given an artificial neural network and an error function, the method
  calculates the gradient of the error function with respect to the neural
  network's weights.</p>
<p>ReLU helps in solving the vanishing gradient problem.</p>
<h2>Neural Network Implementation</h2>
<h3>Feed Forward</h3>
<h3>Back propagation</h3>
<h2>Example</h2>
